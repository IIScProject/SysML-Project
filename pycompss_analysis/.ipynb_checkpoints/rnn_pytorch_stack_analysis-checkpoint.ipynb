{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c7c0423",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycompss.interactive as ipycompss\n",
    "# Import  libraries\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(1, '../')\n",
    "import torch\n",
    "from pycompss.api import task\n",
    "from torch import nn\n",
    "from textCorpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85acafeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding :  torch.Size([300, 49512])\n",
      "Weight :  torch.Size([4, 256, 300])\n",
      "U :  torch.Size([4, 256, 256])\n",
      "V :  torch.Size([4, 300, 256])\n"
     ]
    }
   ],
   "source": [
    "class RNN_stack(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, output_size, stack_length):\n",
    "        super(RNN_stack, self).__init__()\n",
    "        '''\n",
    "        Input Size : 1 * |V| \n",
    "        Embedding Size : d \n",
    "        Embedding Matrix : |V| * d \n",
    "        '''\n",
    "        self.input_size = input_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.stack_length = stack_length\n",
    "\n",
    "        self.embedding = nn.Linear(in_features=input_size, out_features=embedding_size, bias=False)\n",
    "        self.weights = []\n",
    "        self.u_ls = []\n",
    "        self.v_ls = []\n",
    "        for i in range(stack_length):\n",
    "            self.weight = nn.Linear(in_features=embedding_size, out_features=hidden_size, bias=False).to(device)\n",
    "            self.weights.append(self.weight)\n",
    "            self.u = nn.Linear(in_features=hidden_size, out_features=hidden_size, bias=False).to(device)\n",
    "            self.u_ls.append(self.u)\n",
    "            self.v = nn.Linear(in_features=hidden_size, out_features=embedding_size, bias=False).to(device)\n",
    "            self.v_ls.append(self.v)\n",
    "\n",
    "    def encode(self, input):\n",
    "        e = self.embedding(input)\n",
    "        return e\n",
    "\n",
    "    def softmax(self, input):\n",
    "        out = torch.softmax(input, dim=1)\n",
    "        return out\n",
    "\n",
    "    def rnn_cell(self, input, hidden, stack_idx):\n",
    "        input = input.to(device)\n",
    "        hidden = hidden.to(device)\n",
    "        h1 = self.weights[stack_idx](input).to(device)\n",
    "        h2 = self.u_ls[stack_idx](hidden)\n",
    "        h = torch.add(h1, h2)\n",
    "        out = self.v_ls[stack_idx](h)\n",
    "        return out, h\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return nn.init.kaiming_uniform_(torch.empty(self.stack_length, self.hidden_size))\n",
    "\n",
    "    def forward(self, input, hidden_states, stack_length):\n",
    "        # print(\"Input : \", input.shape)\n",
    "        # print(\"Hidden State : \", hidden_states.shape)\n",
    "        # print(\"Stack Len : \", stack_length)\n",
    "        input = self.embedding(input)\n",
    "        for stack_idx in range(stack_length):\n",
    "            output_hat_ls = []\n",
    "            hidden_state = hidden_states[stack_idx]\n",
    "            hidden_state = hidden_state.to(device)\n",
    "            for sequence_length_idx in range(input.shape[1]):\n",
    "                output_hat_vector, hidden_state = self.rnn_cell(input[:, sequence_length_idx, :], hidden_state,\n",
    "                                                                stack_idx)\n",
    "                output_hat_ls.append(output_hat_vector)\n",
    "\n",
    "            output_hat_stack = torch.stack(output_hat_ls, dim=1)\n",
    "            output_hat_stack = output_hat_stack.to(device)\n",
    "            input = output_hat_stack\n",
    "            input = input.to(device)\n",
    "        output_hat_stack = nn.Linear(in_features=embedding_size, out_features=self.output_size, bias=False).to(device)(\n",
    "            output_hat_stack)\n",
    "        output_hat_stack = self.softmax(output_hat_stack)\n",
    "        return output_hat_stack\n",
    "\n",
    "\n",
    "def get_rnn_stack_parameter() -> (torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor):\n",
    "    checkpoint_dir = \"../checkpoints/rnn_pytorch/\"\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, f\"rnn_pytorch_stack.pth\")\n",
    "    model = torch.load(checkpoint_path)\n",
    "\n",
    "    embedding_paramaters = []\n",
    "    for param in model.embedding.parameters():\n",
    "        embedding_paramaters.append(param)\n",
    "\n",
    "    embedding_paramaters = embedding_paramaters[0]\n",
    "\n",
    "    weight_paramaters = []\n",
    "    for i in model.weights:\n",
    "        for param in i.parameters():\n",
    "            weight_paramaters.append(param)\n",
    "\n",
    "    weight_paramaters = torch.stack(weight_paramaters, dim= 0)\n",
    "\n",
    "    u_paramaters = []\n",
    "    for i in model.u_ls:\n",
    "        for param in i.parameters():\n",
    "            u_paramaters.append(param)\n",
    "\n",
    "    u_paramaters = torch.stack(u_paramaters, dim= 0)\n",
    "\n",
    "    v_paramaters = []\n",
    "    for i in model.v_ls:\n",
    "        for param in i.parameters():\n",
    "            v_paramaters.append(param)\n",
    "\n",
    "    v_paramaters = torch.stack(v_paramaters, dim=0)\n",
    "\n",
    "    return embedding_paramaters, weight_paramaters, u_paramaters, v_paramaters\n",
    "\n",
    "def init_hidden(stack_length, hidden_size, mini_batch_size):\n",
    "    hidden = []\n",
    "    for i in range(stack_length) :\n",
    "        mini_batch_hidden = []\n",
    "        value = nn.init.kaiming_uniform_(torch.empty(1, hidden_size))\n",
    "        for i in range(mini_batch_size) :\n",
    "            mini_batch_hidden.append(value)\n",
    "        mini_batch_hidden = torch.concat(mini_batch_hidden)\n",
    "        hidden.append(mini_batch_hidden)\n",
    "\n",
    "    hidden = torch.stack(hidden, dim=0)\n",
    "    return hidden\n",
    "\n",
    "stack_length = 4\n",
    "sequence_length = 4\n",
    "device = \"cpu\"\n",
    "hidden_size = 256\n",
    "mini_batch_size = 512\n",
    "e,w,u,v = get_rnn_stack_parameter()\n",
    "h = init_hidden(stack_length = 4, hidden_size= hidden_size, mini_batch_size= mini_batch_size)\n",
    "print(\"Embedding : \", e.shape)\n",
    "print(\"Weight : \", w.shape)\n",
    "print(\"U : \", u.shape)\n",
    "print(\"V : \", v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ce75bd6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************\n",
      "**************** PyCOMPSs Interactive ******************\n",
      "********************************************************\n",
      "*          .-~~-.--.           ______         ______   *\n",
      "*         :         )         |____  \\       |____  \\  *\n",
      "*   .~ ~ -.\\       /.- ~~ .      __) |          __) |  *\n",
      "*   >       `.   .'       <     |__  |         |__  |  *\n",
      "*  (         .- -.         )   ____) |   _    ____) |  *\n",
      "*   `- -.-~  `- -'  ~-.- -'   |______/  |_|  |______/  *\n",
      "*     (        :        )           _ _ .-:            *\n",
      "*      ~--.    :    .--~        .-~  .-~  }            *\n",
      "*          ~-.-^-.-~ \\_      .~  .-~   .~              *\n",
      "*                   \\ \\ '     \\ '_ _ -~                *\n",
      "*                    \\`.\\`.    //                      *\n",
      "*           . - ~ ~-.__\\`.\\`-.//                       *\n",
      "*       .-~   . - ~  }~ ~ ~-.~-.                       *\n",
      "*     .' .-~      .-~       :/~-.~-./:                 *\n",
      "*    /_~_ _ . - ~                 ~-.~-._              *\n",
      "*                                     ~-.<             *\n",
      "********************************************************\n",
      "* - Starting COMPSs runtime...                         *\n",
      "* - Log path : /home/naman/.COMPSs/Interactive_37/\n",
      "* - PyCOMPSs Runtime started... Have fun!              *\n",
      "********************************************************\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if 'BINDER_SERVICE_HOST' in os.environ:\n",
    "    ipycompss.start(graph=True,\n",
    "                    project_xml='../xml/project.xml',\n",
    "                    resources_xml='../xml/resources.xml')\n",
    "else:\n",
    "    ipycompss.start(graph=True, monitor=1000)  # debug=True, trace=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecabf879",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycompss.api.task import task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7cdf07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found task: compute_sum\n",
      "********************************************************\n",
      "***************** STOPPING PyCOMPSs ********************\n",
      "********************************************************\n",
      "Checking if any issue happened.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ERRMGR]  -  WARNING: Job 1, running Task 1 on worker localhost, has failed.\n",
      "[ERRMGR]  -  WARNING: Resubmitting job to the same worker.\n",
      "[ERRMGR]  -  WARNING: Job 1, running Task 1 on worker localhost, has failed.\n",
      "[ERRMGR]  -  WARNING: Task 1 execution on worker localhost has failed; rescheduling task execution. (changing worker)\n",
      "[ERRMGR]  -  WARNING: Job 2, running Task 1 on worker localhost, has failed.\n",
      "[ERRMGR]  -  WARNING: Resubmitting job to the same worker.\n",
      "[ERRMGR]  -  WARNING: Job 2, running Task 1 on worker localhost, has failed.\n",
      "[ERRMGR]  -  WARNING: Task 1 has already been rescheduled; notifying task failure.\n",
      "[ERRMGR]  -  WARNING: Task 'InteractiveMode_120324_160637.compute_sum' TOTALLY FAILED.\n",
      "[ERRMGR]  -  ERROR:   Task failed: [[Task id: 1], [Status: FAILED], [Core id: 0], [Priority: false], [NumNodes: 1], [MustReplicate: false], [MustDistribute: false], [InteractiveMode_120324_160637.compute_sum(FILE_T, FILE_T, FILE_T)]]\n",
      "[ERRMGR]  -  Shutting down COMPSs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synchronizing all future objects left on the user scope.\n",
      "Found a list to synchronize: tensor_a\n"
     ]
    }
   ],
   "source": [
    "import pycompss.interactive as ipycompss\n",
    "import numpy as np\n",
    "import torch\n",
    "from pycompss.api.task import task\n",
    "from pycompss.api.parameter import Type\n",
    "from pycompss.api.api import barrier\n",
    "\n",
    "\n",
    "@task(returns=list)\n",
    "def compute_sum(tensor_a, tensor_b):\n",
    "    # Convert lists to PyTorch tensors\n",
    "    tensor_a = torch.tensor(tensor_a)\n",
    "    tensor_b = torch.tensor(tensor_b)\n",
    "    return (tensor_a + tensor_b).tolist()\n",
    "\n",
    "# Create lists (which will be converted to PyTorch tensors)\n",
    "tensor_a = [1, 2, 3]\n",
    "tensor_b = [4, 5, 6]\n",
    "    \n",
    "# Execute the function on PyCOMPSs\n",
    "result = compute_sum(tensor_a, tensor_b)\n",
    "barrier()\n",
    "ipycompss.stop(sync=True)\n",
    "# Convert the resulting list back to a PyTorch tensor\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad7afe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47c41eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_stack(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, output_size, stack_length):\n",
    "        super(RNN_stack, self).__init__()\n",
    "        '''\n",
    "        Input Size : 1 * |V| \n",
    "        Embedding Size : d \n",
    "        Embedding Matrix : |V| * d \n",
    "        '''\n",
    "        self.input_size = input_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.stack_length = stack_length\n",
    "\n",
    "        self.embedding = nn.Linear(in_features=input_size, out_features=embedding_size, bias=False)\n",
    "        self.weights = []\n",
    "        self.u_ls = []\n",
    "        self.v_ls = []\n",
    "        for i in range(stack_length):\n",
    "            self.weight = nn.Linear(in_features=embedding_size, out_features=hidden_size, bias=False).to(device)\n",
    "            self.weights.append(self.weight)\n",
    "            self.u = nn.Linear(in_features=hidden_size, out_features=hidden_size, bias=False).to(device)\n",
    "            self.u_ls.append(self.u)\n",
    "            self.v = nn.Linear(in_features=hidden_size, out_features=embedding_size, bias=False).to(device)\n",
    "            self.v_ls.append(self.v)\n",
    "\n",
    "    def encode(self, input):\n",
    "        e = self.embedding(input)\n",
    "        return e\n",
    "\n",
    "    def softmax(self, input):\n",
    "        out = torch.softmax(input, dim=1)\n",
    "        return out\n",
    "\n",
    "    def rnn_cell(self, input, hidden, stack_idx):\n",
    "        input = input.to(device)\n",
    "        hidden = hidden.to(device)\n",
    "        h1 = self.weights[stack_idx](input).to(device)\n",
    "        h2 = self.u_ls[stack_idx](hidden)\n",
    "        h = torch.add(h1, h2)\n",
    "        out = self.v_ls[stack_idx](h)\n",
    "        return out, h\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return nn.init.kaiming_uniform_(torch.empty(self.stack_length, self.hidden_size))\n",
    "\n",
    "    def forward(self, input, hidden_states, stack_length):\n",
    "        # print(\"Input : \", input.shape)\n",
    "        # print(\"Hidden State : \", hidden_states.shape)\n",
    "        # print(\"Stack Len : \", stack_length)\n",
    "        input = self.embedding(input)\n",
    "        for stack_idx in range(stack_length):\n",
    "            output_hat_ls = []\n",
    "            hidden_state = hidden_states[stack_idx]\n",
    "            hidden_state = hidden_state.to(device)\n",
    "            for sequence_length_idx in range(input.shape[1]):\n",
    "                output_hat_vector, hidden_state = self.rnn_cell(input[:, sequence_length_idx, :], hidden_state,\n",
    "                                                                stack_idx)\n",
    "                output_hat_ls.append(output_hat_vector)\n",
    "\n",
    "            output_hat_stack = torch.stack(output_hat_ls, dim=1)\n",
    "            output_hat_stack = output_hat_stack.to(device)\n",
    "            input = output_hat_stack\n",
    "            input = input.to(device)\n",
    "        output_hat_stack = nn.Linear(in_features=embedding_size, out_features=self.output_size, bias=False).to(device)(\n",
    "            output_hat_stack)\n",
    "        output_hat_stack = self.softmax(output_hat_stack)\n",
    "        return output_hat_stack\n",
    "\n",
    "\n",
    "@task()\n",
    "def get_rnn_stack_parameter() -> (torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor):\n",
    "    return torch.tensor([1, 2, 3]), torch.tensor([1, 2, 3]), torch.tensor([1, 2, 3]), torch.tensor([1, 2, 3])\n",
    "    checkpoint_dir = \"../checkpoints/rnn_pytorch/\"\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, f\"rnn_pytorch_stack.pth\")\n",
    "    model = torch.load(checkpoint_path)\n",
    "\n",
    "    embedding_paramaters = []\n",
    "    for param in model.embedding.parameters():\n",
    "        embedding_paramaters.append(param)\n",
    "\n",
    "    embedding_paramaters = embedding_paramaters[0]\n",
    "\n",
    "    weight_paramaters = []\n",
    "    for i in model.weights:\n",
    "        for param in i.parameters():\n",
    "            weight_paramaters.append(param)\n",
    "\n",
    "    weight_paramaters = torch.stack(weight_paramaters, dim= 0)\n",
    "\n",
    "    u_paramaters = []\n",
    "    for i in model.u_ls:\n",
    "        for param in i.parameters():\n",
    "            u_paramaters.append(param)\n",
    "\n",
    "    u_paramaters = torch.stack(u_paramaters, dim= 0)\n",
    "\n",
    "    v_paramaters = []\n",
    "    for i in model.v_ls:\n",
    "        for param in i.parameters():\n",
    "            v_paramaters.append(param)\n",
    "\n",
    "    v_paramaters = torch.stack(v_paramaters, dim=0)\n",
    "\n",
    "    return embedding_paramaters, weight_paramaters, u_paramaters, v_paramaters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c19dc33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found task: get_rnn_stack_parameter\n"
     ]
    }
   ],
   "source": [
    "stack_length = 4\n",
    "sequence_length = 4\n",
    "device = \"cpu\"\n",
    "hidden_size = 256\n",
    "mini_batch_size = 512\n",
    "e,w,u,v = get_rnn_stack_parameter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eab87b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycompss.api.api import compss_wait_on\n",
    "e,w,u,v = compss_wait_on(e,w,u,v)\n",
    "print(\"Embedding : \", e.shape)\n",
    "print(\"Weight : \", w.shape)\n",
    "print(\"U : \", u.shape)\n",
    "print(\"V : \", v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2c6bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipycompss.stop(sync=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347383df",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Results after stopping PyCOMPSs: \")\n",
    "print(\"a: %d\" % a)\n",
    "print(\"b: %d\" % b)\n",
    "print(\"c: %d\" % c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac8f89b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
